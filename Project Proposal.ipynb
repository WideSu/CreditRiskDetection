{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6273aba",
   "metadata": {},
   "source": [
    "# 1. Anni HUANG\n",
    "## 1.1 Online News Popularity(2015)-classification/regression\n",
    "### Problem Statement:\n",
    "\n",
    "Media and newspaper companies want their passages to go viral. But they're so many factors that can contribute to it. Like the date and time when it posts the keywords, the positive and negative words they used, the category of the news, and so on. We propose the study to analyze the factors which lead to the popularity of news. And that will help the editors get more attention from the public.\n",
    "<br>\n",
    "### Data Description\n",
    "This dataset summarizes a heterogeneous set of features about articles published by Mashable in a period of two years. The goal is to predict the number of shares in social networks (popularity).<br>\n",
    "[Data description](https://archive-beta.ics.uci.edu/ml/datasets/online+news+popularity)\n",
    "### Proposed Models\n",
    "Four machine learning models\n",
    "- (a) Linear Regression\n",
    "- (b) Logistic Regression\n",
    "- (c) Ridge Regression\n",
    "- (d) Lasso Regression\n",
    "\n",
    "One deep learning model\n",
    "- (e) CNN\n",
    "\n",
    "### Evaluation Matrix\n",
    "Four performance metrics \n",
    "- Root mean squared error, \n",
    "- Coefficient of Variance, \n",
    "- Mean Absolute Error,\n",
    "- Median Absolute Error\n",
    "\n",
    "will be used on our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4563290f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url   timedelta  \\\n",
       "0  http://mashable.com/2013/01/07/amazon-instant-...       731.0   \n",
       "1  http://mashable.com/2013/01/07/ap-samsung-spon...       731.0   \n",
       "2  http://mashable.com/2013/01/07/apple-40-billio...       731.0   \n",
       "3  http://mashable.com/2013/01/07/astronaut-notre...       731.0   \n",
       "4   http://mashable.com/2013/01/07/att-u-verse-apps/       731.0   \n",
       "\n",
       "    n_tokens_title   n_tokens_content   n_unique_tokens   n_non_stop_words  \\\n",
       "0             12.0              219.0          0.663594                1.0   \n",
       "1              9.0              255.0          0.604743                1.0   \n",
       "2              9.0              211.0          0.575130                1.0   \n",
       "3              9.0              531.0          0.503788                1.0   \n",
       "4             13.0             1072.0          0.415646                1.0   \n",
       "\n",
       "    n_non_stop_unique_tokens   num_hrefs   num_self_hrefs   num_imgs  ...  \\\n",
       "0                   0.815385         4.0              2.0        1.0  ...   \n",
       "1                   0.791946         3.0              1.0        1.0  ...   \n",
       "2                   0.663866         3.0              1.0        1.0  ...   \n",
       "3                   0.665635         9.0              0.0        1.0  ...   \n",
       "4                   0.540890        19.0             19.0       20.0  ...   \n",
       "\n",
       "    min_positive_polarity   max_positive_polarity   avg_negative_polarity  \\\n",
       "0                0.100000                     0.7               -0.350000   \n",
       "1                0.033333                     0.7               -0.118750   \n",
       "2                0.100000                     1.0               -0.466667   \n",
       "3                0.136364                     0.8               -0.369697   \n",
       "4                0.033333                     1.0               -0.220192   \n",
       "\n",
       "    min_negative_polarity   max_negative_polarity   title_subjectivity  \\\n",
       "0                  -0.600               -0.200000             0.500000   \n",
       "1                  -0.125               -0.100000             0.000000   \n",
       "2                  -0.800               -0.133333             0.000000   \n",
       "3                  -0.600               -0.166667             0.000000   \n",
       "4                  -0.500               -0.050000             0.454545   \n",
       "\n",
       "    title_sentiment_polarity   abs_title_subjectivity  \\\n",
       "0                  -0.187500                 0.000000   \n",
       "1                   0.000000                 0.500000   \n",
       "2                   0.000000                 0.500000   \n",
       "3                   0.000000                 0.500000   \n",
       "4                   0.136364                 0.045455   \n",
       "\n",
       "    abs_title_sentiment_polarity   shares  \n",
       "0                       0.187500      593  \n",
       "1                       0.000000      711  \n",
       "2                       0.000000     1500  \n",
       "3                       0.000000     1200  \n",
       "4                       0.136364      505  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df11 = pd.read_csv(\"OnlineNewsPopularity.csv\")\n",
    "df11.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "354b8cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39644 entries, 0 to 39643\n",
      "Data columns (total 61 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   url                             39644 non-null  object \n",
      " 1    timedelta                      39644 non-null  float64\n",
      " 2    n_tokens_title                 39644 non-null  float64\n",
      " 3    n_tokens_content               39644 non-null  float64\n",
      " 4    n_unique_tokens                39644 non-null  float64\n",
      " 5    n_non_stop_words               39644 non-null  float64\n",
      " 6    n_non_stop_unique_tokens       39644 non-null  float64\n",
      " 7    num_hrefs                      39644 non-null  float64\n",
      " 8    num_self_hrefs                 39644 non-null  float64\n",
      " 9    num_imgs                       39644 non-null  float64\n",
      " 10   num_videos                     39644 non-null  float64\n",
      " 11   average_token_length           39644 non-null  float64\n",
      " 12   num_keywords                   39644 non-null  float64\n",
      " 13   data_channel_is_lifestyle      39644 non-null  float64\n",
      " 14   data_channel_is_entertainment  39644 non-null  float64\n",
      " 15   data_channel_is_bus            39644 non-null  float64\n",
      " 16   data_channel_is_socmed         39644 non-null  float64\n",
      " 17   data_channel_is_tech           39644 non-null  float64\n",
      " 18   data_channel_is_world          39644 non-null  float64\n",
      " 19   kw_min_min                     39644 non-null  float64\n",
      " 20   kw_max_min                     39644 non-null  float64\n",
      " 21   kw_avg_min                     39644 non-null  float64\n",
      " 22   kw_min_max                     39644 non-null  float64\n",
      " 23   kw_max_max                     39644 non-null  float64\n",
      " 24   kw_avg_max                     39644 non-null  float64\n",
      " 25   kw_min_avg                     39644 non-null  float64\n",
      " 26   kw_max_avg                     39644 non-null  float64\n",
      " 27   kw_avg_avg                     39644 non-null  float64\n",
      " 28   self_reference_min_shares      39644 non-null  float64\n",
      " 29   self_reference_max_shares      39644 non-null  float64\n",
      " 30   self_reference_avg_sharess     39644 non-null  float64\n",
      " 31   weekday_is_monday              39644 non-null  float64\n",
      " 32   weekday_is_tuesday             39644 non-null  float64\n",
      " 33   weekday_is_wednesday           39644 non-null  float64\n",
      " 34   weekday_is_thursday            39644 non-null  float64\n",
      " 35   weekday_is_friday              39644 non-null  float64\n",
      " 36   weekday_is_saturday            39644 non-null  float64\n",
      " 37   weekday_is_sunday              39644 non-null  float64\n",
      " 38   is_weekend                     39644 non-null  float64\n",
      " 39   LDA_00                         39644 non-null  float64\n",
      " 40   LDA_01                         39644 non-null  float64\n",
      " 41   LDA_02                         39644 non-null  float64\n",
      " 42   LDA_03                         39644 non-null  float64\n",
      " 43   LDA_04                         39644 non-null  float64\n",
      " 44   global_subjectivity            39644 non-null  float64\n",
      " 45   global_sentiment_polarity      39644 non-null  float64\n",
      " 46   global_rate_positive_words     39644 non-null  float64\n",
      " 47   global_rate_negative_words     39644 non-null  float64\n",
      " 48   rate_positive_words            39644 non-null  float64\n",
      " 49   rate_negative_words            39644 non-null  float64\n",
      " 50   avg_positive_polarity          39644 non-null  float64\n",
      " 51   min_positive_polarity          39644 non-null  float64\n",
      " 52   max_positive_polarity          39644 non-null  float64\n",
      " 53   avg_negative_polarity          39644 non-null  float64\n",
      " 54   min_negative_polarity          39644 non-null  float64\n",
      " 55   max_negative_polarity          39644 non-null  float64\n",
      " 56   title_subjectivity             39644 non-null  float64\n",
      " 57   title_sentiment_polarity       39644 non-null  float64\n",
      " 58   abs_title_subjectivity         39644 non-null  float64\n",
      " 59   abs_title_sentiment_polarity   39644 non-null  float64\n",
      " 60   shares                         39644 non-null  int64  \n",
      "dtypes: float64(59), int64(1), object(1)\n",
      "memory usage: 18.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df11.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0d7136",
   "metadata": {},
   "source": [
    "## 1.2 Trip duration(2020)-regression\n",
    "### Problem Statement\n",
    "Trip duration is the most fundamental measure in all modes of transportation. Hence, it is crucial to predict the trip-time precisely for the advancement of Intelligent Transport Systems (ITS) and traveller information systems. In order to predict the trip duration, data mining techniques are employed to predict the trip duration of rental bikes in Seoul Bike sharing system. The prediction is carried out with the combination of Seoul Bike data and weather data.\n",
    "### Data Description\n",
    "The Data used include trip duration, trip distance, pickup-dropoff latitude and longitude, temperature, precipitation, wind speed, humidity, solar radiation, snowfall, ground temperature and 1-hour average dust concentration. Feature engineering is done to extract additional features from the data. \n",
    "### Proposed Models\n",
    "Four statistical models are used to predict the trip duration. \n",
    "- (a) Linear regression, \n",
    "- (b) Gradient boosting machines, \n",
    "- (c) k nearest neighbor and \n",
    "- (d) Random Forest(RF). \n",
    "\n",
    "One Deep Learning model is used to predict the trip duration.\n",
    "- (e) CNN\n",
    "\n",
    "### Evaluation Metrix\n",
    "Four performance metrics \n",
    "- Root mean squared error, \n",
    "- Coefficient of Variance, \n",
    "- Mean Absolute Error,\n",
    "- Median Absolute Error\n",
    "\n",
    "is used to determine the efficiency of the models. In comparison with the other models, the optimum model RF can explain the variance of 93% in the testing set and 98% (R2) in the training set. The outcome proves that RF is effective to be employed for the prediction of trip duration.\n",
    "<br>\n",
    "[Dataset description](https://plu.mx/plum/a/?mendeley_data_id=gtfh9z865f&theme=plum-bigben-theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66315b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12 = pd.read_csv(\"For_modeling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f810a0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Distance</th>\n",
       "      <th>PLong</th>\n",
       "      <th>PLatd</th>\n",
       "      <th>DLong</th>\n",
       "      <th>DLatd</th>\n",
       "      <th>Haversine</th>\n",
       "      <th>Pmonth</th>\n",
       "      <th>Pday</th>\n",
       "      <th>...</th>\n",
       "      <th>Dmin</th>\n",
       "      <th>DDweek</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Precip</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Humid</th>\n",
       "      <th>Solar</th>\n",
       "      <th>Snow</th>\n",
       "      <th>GroundTemp</th>\n",
       "      <th>Dust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>37.544666</td>\n",
       "      <td>126.888359</td>\n",
       "      <td>37.544666</td>\n",
       "      <td>126.888359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>7670</td>\n",
       "      <td>37.506199</td>\n",
       "      <td>127.003944</td>\n",
       "      <td>37.551250</td>\n",
       "      <td>127.035103</td>\n",
       "      <td>5.713529</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1390</td>\n",
       "      <td>37.544590</td>\n",
       "      <td>127.057083</td>\n",
       "      <td>37.537014</td>\n",
       "      <td>127.061096</td>\n",
       "      <td>0.913702</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1820</td>\n",
       "      <td>37.571102</td>\n",
       "      <td>127.023560</td>\n",
       "      <td>37.561447</td>\n",
       "      <td>127.034920</td>\n",
       "      <td>1.468027</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>850</td>\n",
       "      <td>37.573242</td>\n",
       "      <td>127.015907</td>\n",
       "      <td>37.565849</td>\n",
       "      <td>127.016403</td>\n",
       "      <td>0.823227</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Duration  Distance      PLong       PLatd      DLong  \\\n",
       "0           0         3        50  37.544666  126.888359  37.544666   \n",
       "1           1        24      7670  37.506199  127.003944  37.551250   \n",
       "2           2         8      1390  37.544590  127.057083  37.537014   \n",
       "3           3         8      1820  37.571102  127.023560  37.561447   \n",
       "4           4         4       850  37.573242  127.015907  37.565849   \n",
       "\n",
       "        DLatd  Haversine  Pmonth  Pday  ...  Dmin  DDweek  Temp  Precip  Wind  \\\n",
       "0  126.888359   0.000000       1     1  ...     4       0  -3.2     0.0   0.5   \n",
       "1  127.035103   5.713529       1     1  ...    25       0  -3.2     0.0   0.5   \n",
       "2  127.061096   0.913702       1     1  ...     9       0  -3.2     0.0   0.5   \n",
       "3  127.034920   1.468027       1     1  ...    10       0  -3.2     0.0   0.5   \n",
       "4  127.016403   0.823227       1     1  ...     6       0  -3.2     0.0   0.5   \n",
       "\n",
       "   Humid  Solar  Snow  GroundTemp  Dust  \n",
       "0   40.0    0.0   0.0        -2.2  25.0  \n",
       "1   40.0    0.0   0.0        -2.2  25.0  \n",
       "2   40.0    0.0   0.0        -2.2  25.0  \n",
       "3   40.0    0.0   0.0        -2.2  25.0  \n",
       "4   40.0    0.0   0.0        -2.2  25.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58379e07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9601139 entries, 0 to 9601138\n",
      "Data columns (total 26 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   Unnamed: 0  int64  \n",
      " 1   Duration    int64  \n",
      " 2   Distance    int64  \n",
      " 3   PLong       float64\n",
      " 4   PLatd       float64\n",
      " 5   DLong       float64\n",
      " 6   DLatd       float64\n",
      " 7   Haversine   float64\n",
      " 8   Pmonth      int64  \n",
      " 9   Pday        int64  \n",
      " 10  Phour       int64  \n",
      " 11  Pmin        int64  \n",
      " 12  PDweek      int64  \n",
      " 13  Dmonth      int64  \n",
      " 14  Dday        int64  \n",
      " 15  Dhour       int64  \n",
      " 16  Dmin        int64  \n",
      " 17  DDweek      int64  \n",
      " 18  Temp        float64\n",
      " 19  Precip      float64\n",
      " 20  Wind        float64\n",
      " 21  Humid       float64\n",
      " 22  Solar       float64\n",
      " 23  Snow        float64\n",
      " 24  GroundTemp  float64\n",
      " 25  Dust        float64\n",
      "dtypes: float64(13), int64(13)\n",
      "memory usage: 1.9 GB\n"
     ]
    }
   ],
   "source": [
    "df12.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b16e8b",
   "metadata": {},
   "source": [
    "# 2 Rao Ningzhen\n",
    "## 2.1 Backorder Prediction(2021) - regression/classification\n",
    "### Backorder Defination:\n",
    "A backorder generally indicates that customer demand for a product or service exceeds a company’s capacity to supply it. Product backorder may be the result of strong sales performance (e.g. the product is in such high demand that production cannot keep up with sales). However, backorders can upset consumers, lead to canceled orders and decreased customer loyalty. Companies want to avoid backorders, but also avoid overstocking every product (leading to higher inventory costs). Machine learning can identify patterns related to backorders before customers order. Production can then adjust to minimize delays while customer service can provide accurate dates to keep customers informed and happy. The predictive analytics approach enables the maximum product to get in the hands of customers at the lowest cost to the organization.\n",
    "A backorder is an order (or part of an order) waiting to be filled, usually because the merchant in question does not have that item currently stocked in the warehouse.\n",
    "### Problem Statement:\n",
    "In supply chain system, Material backorder is a common problem, impacting an inventory system service level and effectiveness. Identifying parts with the highest chances of shortage prior its occurrence can present a high opportunity to improve an overall company’s performance. In this project, we will train classifiers to predict future backordered products and generate predictions for a test set.<br>\n",
    "[Data Description](https://www.kaggle.com/chandanareddy12/back-order-prediction)\n",
    "### Data Fields\n",
    "- sku - sku code\n",
    "- nationalinv - Current inventory level of component\n",
    "- leadtime - Transit time\n",
    "- in transit qty - Quantity in transit\n",
    "- forecastxmonth - Forecast sales for the net 3, 6, 9 months\n",
    "- salesxmonth - Sales quantity for the prior 1, 3, 6, 9 months\n",
    "- minbank - Minimum recommended amount in stock • potentialissue - Indictor variable noting potential issue with item\n",
    "- pieces past due - Parts overdue from source\n",
    "- perfxmonthsavg - Source performance in the last 6 and 12 months \n",
    "- localboqty - Amount of stock orders overdue \n",
    "- X17-X22 - General Risk Flags \n",
    "- wentonbackorder - Product went on backorder\n",
    "### Proposed Models\n",
    "Four statistical models are used to predict the trip duration. \n",
    "- (a) Linear regression, \n",
    "- (b) Gradient boosting machines, \n",
    "- (c) k nearest neighbor and \n",
    "- (d) Random Forest(RF). \n",
    "One Deep Learning model is used to predict the trip duration.\n",
    "- (e) CNN\n",
    "### Evaluation Metrix\n",
    "Four performance metrics \n",
    "- Root mean squared error, \n",
    "- Coefficient of Variance, \n",
    "- Mean Absolute Error,\n",
    "- Median Absolute Error\n",
    "\n",
    "is used to determine the efficiency of the models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9679225",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>national_inv</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>in_transit_qty</th>\n",
       "      <th>forecast_3_month</th>\n",
       "      <th>forecast_6_month</th>\n",
       "      <th>forecast_9_month</th>\n",
       "      <th>sales_1_month</th>\n",
       "      <th>sales_3_month</th>\n",
       "      <th>sales_6_month</th>\n",
       "      <th>...</th>\n",
       "      <th>pieces_past_due</th>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <th>local_bo_qty</th>\n",
       "      <th>deck_risk</th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "      <th>went_on_backorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1026827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1043384</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1043696</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1043852</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1044048</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sku  national_inv  lead_time  in_transit_qty  forecast_3_month  \\\n",
       "0  1026827           0.0        NaN             0.0               0.0   \n",
       "1  1043384           2.0        9.0             0.0               0.0   \n",
       "2  1043696           2.0        NaN             0.0               0.0   \n",
       "3  1043852           7.0        8.0             0.0               0.0   \n",
       "4  1044048           8.0        NaN             0.0               0.0   \n",
       "\n",
       "   forecast_6_month  forecast_9_month  sales_1_month  sales_3_month  \\\n",
       "0               0.0               0.0            0.0            0.0   \n",
       "1               0.0               0.0            0.0            0.0   \n",
       "2               0.0               0.0            0.0            0.0   \n",
       "3               0.0               0.0            0.0            0.0   \n",
       "4               0.0               0.0            0.0            0.0   \n",
       "\n",
       "   sales_6_month  ...  pieces_past_due  perf_6_month_avg perf_12_month_avg  \\\n",
       "0            0.0  ...              0.0            -99.00            -99.00   \n",
       "1            0.0  ...              0.0              0.99              0.99   \n",
       "2            0.0  ...              0.0            -99.00            -99.00   \n",
       "3            0.0  ...              0.0              0.10              0.13   \n",
       "4            0.0  ...              0.0            -99.00            -99.00   \n",
       "\n",
       "   local_bo_qty  deck_risk  oe_constraint  ppap_risk stop_auto_buy rev_stop  \\\n",
       "0           0.0         No             No         No           Yes       No   \n",
       "1           0.0         No             No         No           Yes       No   \n",
       "2           0.0        Yes             No         No           Yes       No   \n",
       "3           0.0         No             No         No           Yes       No   \n",
       "4           0.0        Yes             No         No           Yes       No   \n",
       "\n",
       "  went_on_backorder  \n",
       "0                No  \n",
       "1                No  \n",
       "2                No  \n",
       "3                No  \n",
       "4                No  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df21 = pd.read_csv(\"Back_order_train.csv\")\n",
    "df21.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f1f49b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1687861 entries, 0 to 1687860\n",
      "Data columns (total 23 columns):\n",
      " #   Column             Non-Null Count    Dtype  \n",
      "---  ------             --------------    -----  \n",
      " 0   sku                1687861 non-null  object \n",
      " 1   national_inv       1687860 non-null  float64\n",
      " 2   lead_time          1586967 non-null  float64\n",
      " 3   in_transit_qty     1687860 non-null  float64\n",
      " 4   forecast_3_month   1687860 non-null  float64\n",
      " 5   forecast_6_month   1687860 non-null  float64\n",
      " 6   forecast_9_month   1687860 non-null  float64\n",
      " 7   sales_1_month      1687860 non-null  float64\n",
      " 8   sales_3_month      1687860 non-null  float64\n",
      " 9   sales_6_month      1687860 non-null  float64\n",
      " 10  sales_9_month      1687860 non-null  float64\n",
      " 11  min_bank           1687860 non-null  float64\n",
      " 12  potential_issue    1687860 non-null  object \n",
      " 13  pieces_past_due    1687860 non-null  float64\n",
      " 14  perf_6_month_avg   1687860 non-null  float64\n",
      " 15  perf_12_month_avg  1687860 non-null  float64\n",
      " 16  local_bo_qty       1687860 non-null  float64\n",
      " 17  deck_risk          1687860 non-null  object \n",
      " 18  oe_constraint      1687860 non-null  object \n",
      " 19  ppap_risk          1687860 non-null  object \n",
      " 20  stop_auto_buy      1687860 non-null  object \n",
      " 21  rev_stop           1687860 non-null  object \n",
      " 22  went_on_backorder  1687860 non-null  object \n",
      "dtypes: float64(15), object(8)\n",
      "memory usage: 296.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df21.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94228bb",
   "metadata": {},
   "source": [
    "# 3 Ren Xuezhe\n",
    "## 3.1 Home Credit Group(2019)-classification/regression\n",
    "### Problem statement:\n",
    "Many people struggle to get loans due to insufficient or non-existent credit histories. And, unfortunately, this population is often taken advantage of by untrustworthy lenders.\n",
    "\n",
    "### Home Credit Group\n",
    "\n",
    "Home Credit strives to broaden financial inclusion for the unbanked population by providing a positive and safe borrowing experience. In order to make sure this underserved population has a positive loan experience, Home Credit makes use of a variety of alternative data--including telco and transactional information--to predict their clients' repayment abilities.\n",
    "\n",
    "While Home Credit is currently using various statistical and machine learning methods to make these predictions, they're challenging Kagglers to help them unlock the full potential of their data. Doing so will ensure that clients capable of repayment are not rejected and that loans are given with a principal, maturity, and repayment calendar that will empower their clients to be successful.\n",
    "\n",
    "[Data Description](https://www.kaggle.com/c/home-credit-default-risk/overview)\n",
    "![image](https://user-images.githubusercontent.com/44923423/150918954-1c6df444-bb94-4b2e-b7cb-1180540578a7.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09a43d6",
   "metadata": {},
   "source": [
    "# 4 Ding Yanmu\n",
    "OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d383f79f",
   "metadata": {},
   "source": [
    "# 5 Yu Di\n",
    " - Task: regression\n",
    " - Link: https://www.yelp.com/dataset\n",
    " - Dataset Name : Yelp\n",
    " - Models: lightGBM,DRF,NeuMF,BPRMF, deepconn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
